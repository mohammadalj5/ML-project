# -*- coding: utf-8 -*-
"""Ù…Ø´Ø±ÙˆØ¹

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wI3G-ulfFmr8A79okp1Lr3yqHtfOksDK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

df = pd.read_csv('Healthcare.csv')

print("Dataset Shape:", df.shape)
print("\nDataset Features:", list(df.columns))
print("\nNumber of Features:", len(df.columns)-1)
print("\nDataset First Rows:\n", df.head())

if 'Patient_ID' in df.columns:
    df.drop('Patient_ID', axis=1, inplace=True)

df.dropna(inplace=True)

# Target Encoding
le_disease = LabelEncoder()
df['Disease'] = le_disease.fit_transform(df['Disease'])

# Symptoms Encoding
le_symptoms = LabelEncoder()
df['Symptoms'] = le_symptoms.fit_transform(df['Symptoms'].astype(str))

# Gender Encoding
df['Gender'] = df['Gender'].map({'Male':0,'Female':1,'Other':2})
df.dropna(subset=['Gender'], inplace=True)

X = df.drop('Disease', axis=1)
y = df['Disease']

# Balance Check Before
print("\nDisease Distribution BEFORE SMOTE:\n", y.value_counts())

# SMOTE
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X, y)

print("\nDisease Distribution AFTER SMOTE:\n", y_balanced.value_counts())

#==============================================
#   SPLITTING
#==============================================

X_temp, X_test, y_temp, y_test = train_test_split(X_balanced, y_balanced, test_size=0.15, random_state=42, stratify=y_balanced)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)

print("\nTrain Shape:", X_train.shape)
print("Validation Shape:", X_val.shape)
print("Test Shape:", X_test.shape)

# SCALING
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

#   MODELS + PARAMS
#==============================================

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

model_params = {
    'Decision Tree': {
        'model': DecisionTreeClassifier(random_state=42),
        'params': {
            'max_depth':[5,10,20,None],
            'criterion':['gini','entropy']
        }},
    'Random Forest':{
        'model':RandomForestClassifier(random_state=42),
        'params':{
            'n_estimators':[50,100],
            'max_depth':[10,20,None]
        }},
    'SVM':{
        'model':SVC(random_state=42),
        'params':{
            'C':[0.1,1,10],
            'kernel':['rbf','linear']
        }},
    'Logistic Regression':{
        'model':LogisticRegression(max_iter=1000,random_state=42),
        'params':{
            'C':[0.1,1,10],
            'solver':['lbfgs','liblinear']
        }}
}

results = []

print("\n=== Running Grid Search... ===")

best_models = {}

for model_name, mp in model_params.items():
    clf = GridSearchCV(mp['model'], mp['params'], cv=5, scoring='accuracy')

clf.fit(X_train_scaled, y_train)

best_models[model_name] = clf.best_estimator_
results.append({
        'Model': model_name,
        'Best CV Score': clf.best_score_,
        'Best Params': clf.best_params_
    })

print(f"\nğŸ”» {model_name} Best Validation Accuracy (CV): {clf.best_score_:.4f}")

print("Best Params:", clf.best_params_)

#   MODEL EVALUATION
#==============================================

print("\n====== Test Evaluation ======")
for name, model in best_models.items():
    print(f"\n----- {name} -----")

# Validation Accuracy
    val_pred = model.predict(X_val_scaled)
    val_acc = accuracy_score(y_val, val_pred)
    print(f"Validation Accuracy: {val_acc:.4f}")

# Test Accuracy
test_pred = model.predict(X_test_scaled)
test_acc = accuracy_score(y_test, test_pred)
print(f"Test Accuracy: {test_acc:.4f}")

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, test_pred, zero_division=0))

# CONFUSION MATRIX
cm = confusion_matrix(y_test, test_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title(f"Confusion Matrix - {name}")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

#   TEXT RESULTS ANALYSIS
#==============================================

print("\n\n===== INTERPRETATION & DISCUSSION =====")

print("""
âœ” Decision Tree:
    Ø³Ù‡Ù„ Ø§Ù„ØªÙØ³ÙŠØ± Ù„ÙƒÙ†Ù‡ Ù‚Ø¯ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† overfitting.

âœ” Random Forest:
    ØºØ§Ù„Ø¨Ù‹Ø§ Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ø£Ù†Ù‡ ÙŠÙ‚Ù„Ù„ Ø§Ù„Ù€ overfitting ÙˆÙŠØ¹Ø·ÙŠ Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø©.

âœ” SVM:
    ÙŠØªØ¹Ø§Ù…Ù„ Ø¬ÙŠØ¯Ù‹Ø§ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø© ÙˆØ§Ù„Ù€ margin Ø§Ù„Ø¹Ø§Ù„ÙŠ.

âœ” Logistic Regression:
    Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ©ØŒ ÙˆÙ‚Ø¯ ÙŠÙØ´Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙØµÙ„ ØºÙŠØ± Ø®Ø·ÙŠ.

""")

print("""
===== Dataset Analysis =====
Ø§Ù„Ø¯Ø§ØªØ§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ ØµØ­ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø¹Ù…Ø± ÙˆØ§Ù„Ø¬Ù†Ø³ ÙˆØ§Ù„Ø£Ø¹Ø±Ø§Ø¶ ÙˆÙ‚Ø±Ø§Ø¡Ø§Øª Ø·Ø¨ÙŠØ©ØŒ
ÙˆØªÙ‡Ø¯Ù Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨ÙˆØ¬ÙˆØ¯ Ù…Ø±Ø¶ Ù…Ø¹ÙŠÙ†. Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø© Ø¨Ø¹Ø¯ SMOTE ÙŠØ³Ù…Ø­ Ø¨Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø§Ø¯Ù„Ø©.
""")

print("""
===== Validation VS Test Performance =====
Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† accuracies Ø¨ÙŠÙ† validation Ùˆ test Ù…ØªÙ‚Ø§Ø±Ø¨Ø©ØŒ ÙˆÙ‡Ø°Ø§ Ø¯Ù„ÙŠÙ„ Ø£Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø§ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† overfitting Ø­Ø§Ø¯.
Ø¥Ø°Ø§ Ù„Ø§Ø­Ø¸Ù†Ø§ ÙØ±Ù‚Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ overfitting Ø£Ùˆ underfitting.
""")

print("""
===== CONFUSION MATRIX USE =====
Ø®Ø±ÙŠØ·Ø© Ø§Ù„ confusion matrix ØªÙˆØ¶Ø­ Ø¯Ù‚Ø© ÙƒÙ„ class ØªØ­Ø¯ÙŠØ¯Ù‹Ø§ØŒ
ÙˆØªÙƒØ´Ù Ø£ÙŠÙ† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ ÙˆÙ„ÙŠØ³ ÙÙ‚Ø· Ù†Ø³Ø¨Ø© accuracy Ø§Ù„Ø¹Ø§Ù…Ø©.
""")

print("""
===== FINAL CONCLUSION =====
Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ø±ØŒ
RandomForest ÙˆSVM Ù‡Ù… Ø§Ù„Ø£ÙØ¶Ù„ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø©ØŒ
ÙˆØ§Ù„Ø¯Ø§ØªØ§ Ø¨Ø¹Ø¯ SMOTE Ø£ØµØ¨Ø­Øª Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ØªØ¹Ù„Ù….
""")